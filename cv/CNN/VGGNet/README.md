# tensorflow 实现VGGNET

· VGGNET探索了卷积神经网络的深度与性能之间的关系，成功构筑了16~19层深的CNN。

· 全部使用了3×3的卷积核和2×2的池化核，通过加深网络结构来提升性能

· 卷积部分虽然很深，但是消耗的参数量不大，但是计算量大，所以耗时长。全连接参数量大。

· 1×1卷积的意义：线性变换。而输入通道数和输出通道数不变，没有发生降维。

## VGGNET主要思想

· VGGNET拥有5段卷积，每一段有2~3个卷积层，同时每段尾部都会链接一个最大池化层来缩小图片尺寸。每段内的卷积核数量一样，越靠后的段的卷积核数量越多：64-128-256-512-512。其中经常出现多个完全一样的3×3的卷积层堆叠在一起的情况，这其实是非常有用的设计。如图3所示，两个3×3的卷积层串联相当于1个5×5的卷积层，即一个像素会跟周围5×5的像素产生关联，可以说感受野大小为5×5。而3个3×3的卷积层串联的效果则相当于1个7×7的卷积层。除此之外，3个串联的3×3的卷积层，拥有比1个7×7的卷积层更少的参数量，只有后者的(3×3×3)/(7×7)=55%。最重要的是，3个3×3的卷积层拥有比1个7×7的卷积层更多的非线性变换（前者可以使用三次ReLU激活函数，而后者只有一次），使得CNN对特征的学习能力更强。

## VGGNet训练、预测技巧

· VGGNet在训练时有一个小技巧，先训练级别A的简单网络，再复用A网络的权重来初始化后面的几个复杂模型，这样训练收敛的速度更快。

（1）在预测时，VGG采用Multi-Scale的方法，将图像scale到一个尺寸Q，并将图片输入卷积网络计算。然后在最后一个卷积层使用滑窗的方式进行分类预测，将不同窗口的分类结果平均，再将不同尺寸Q的结果平均得到最后结果，这样可提高图片数据的利用率并提升预测准确率。

（2）在训练中，VGGNet还使用了Multi-Scale的方法做数据增强，将原始图像缩放到不同尺寸S，然后再随机裁切224´224的图片，这样能增加很多数据量，对于防止模型过拟合有很不错的效果。

## 作者在对比各级网络时总结出了以下几个观点：

（1）LRN层作用不大

（2）越深的网络效果越好

（3）1×1的卷积也是很有效的，但是没有3×3的卷积好，大一些的卷积核可以学习更大的空间特征。
