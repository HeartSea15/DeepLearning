# Tensorflow实现基于LSTM的语言模型
## LSTM的语言模型简介
LSTM（Long Short Term Memory）,用来处理有时序联系的信息效果非常明显，在很多情况下，卷积神经网络虽然处理图片增加了其空间特征的联系，但是对于图片与图片之间的联系性并不是很强，所以对于视频或者是自然语言处理前后的关联性并不是很好。 对于一些简单的问题，可能只需要最后输入的少量时序信息即可解决问题。但对于复杂问题，可能需要更早的一些信息，甚至是时间序列的开头信息，但间隔太久的信息RNN无法捕获的，所以LSTM的发明就是为了解决这个问题

LSTM包括了四层神经网络，圆圈是point-wise的操作，比如向量加法、点乘等。小矩形代表一层可学习参数的神经网络。LSTM单元上面的那条直线代表了LSTM的状态state,它会贯穿所有连接在一起的LSTM单元，从第一个LSTM单元一直流向最后一个LSTM单元，其中只有少量的线性干预和改变。状态state在这条隧道中传递时，LSTM单元可以对其添加或者删减信息，这些对信息流的修改操作由LSTM中的Gates控制。这些Gates中包含了一个Sigmoid层和一个向量的点乘的操作，这个Sigmoid层的输出时0到1之间的值，它直接控制了信息传递的比例。如果为0则代表不允许信息传递，如果为1，则表示信息全部通过。每个LSTM单元包含3个这样的Gates，用来维护和控制单元的状态信息。凭借对状态信息的储存和修改，LSTM单元就可以实现长程记忆
## 官方论文
http://colah.github.io/posts/2015-08-Understanding-LSTMs/

## 文件介绍
exert_LSTM --   主程序

其余程序是生成数据用，数据源是github开源TensorFlow models库中，models/tutorials/rnn/pdb
